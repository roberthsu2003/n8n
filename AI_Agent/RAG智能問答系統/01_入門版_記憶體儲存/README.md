# 🎯 RAG 入門版 - 記憶體儲存

> 工作流範例名稱:**RAG入門_記憶體儲存**

## 📖 什麼是這個範例？

這是 **最簡單的 RAG 實作**，讓您在 5 分鐘內體驗 RAG（檢索增強生成）技術的魅力！

整個系統只需要**一個工作流程**，就能實現：
- 📤 上傳文件（PDF,CSV,TXT）
- 🔍 自動建立向量索引
- 💬 智能問答對話（支援中文提問，英文檢索，中文回答）

### 🌍 範例特色：英文資料轉英文向量架構

此範例採用「**英轉英**」架構：
- 📄 **上傳英文檔案**：使用英文 Embedding 模型（`sentence-transformers/all-MiniLM-L6-v2`）獲得最佳檢索效果
- 💬 **中文提問**：使用者可以用繁體中文提問
- 🔄 **自動翻譯**：系統自動將中文問題轉換為英文進行向量檢索
- ✅ **中文回答**：AI 根據檢索到的英文資料生成繁體中文回答

**為什麼這樣設計？**
- 英文 Embedding 模型對英文文件的檢索效果最佳
- 使用者可以用熟悉的語言（中文）提問
- 系統自動處理語言轉換，無需手動翻譯

### 範例知識庫文件下載

[範例知識庫文件下載](../知識庫文件)

**建議使用**：`信用卡權益說明_en.txt`（英文檔案）

## ✨ 核心特色

### **為什麼從這裡開始？**

| 特點 | 說明 |
|------|------|
| 🚀 **超級簡單** | 只需一個工作流程，5分鐘快速體驗 |
| 💾 **記憶體儲存** | 使用 In-Memory Vector Store，無需外部資料庫 |
| 🆓 **零成本** | 使用 HuggingFace 免費嵌入模型 + Ollama 本地模型 |
| ⚡ **即時體驗** | 上傳檔案後立即可以開始問答 |
| 📚 **學習友善** | 專注於 RAG 核心概念，無額外複雜度 |
| 🌍 **多語言支援** | 支援中文提問，英文檢索，中文回答 |

### **適用場景**

✅ RAG 技術學習和概念驗證  
✅ 快速測試和演示  
✅ 個人小規模使用（少量文件）  
✅ 教學和實驗

### **限制與注意事項**

⚠️ **資料不持久**：工作流程重啟或執行結束後，向量資料會消失  
⚠️ **不適合大量文件**：記憶體有限，建議小於 50 份文件  
⚠️ **無法跨流程共用**：每次執行都是獨立的索引  
⚠️ **適合測試**：生產環境建議使用基礎版或進階版  
⚠️ **英轉英範例**：此範例針對英文檔案優化，請上傳英文檔案以獲得最佳效果  
⚠️ **需要 Ollama**：需要本地安裝並運行 Ollama 服務

---

## 🎓 什麼是 RAG？

**RAG (Retrieval-Augmented Generation)** = 檢索增強生成

簡單來說，RAG 讓 AI 能夠：
1. 📖 **讀取**您的文件
2. 🔍 **檢索**相關資訊
3. 💬 **回答**基於文件內容的問題

### **RAG 的工作流程**

```
┌─────────────────────────────────────────────┐
│          RAG 工作流程（入門版）              │
├─────────────────────────────────────────────┤
│                                             │
│  Step 1: 📤 上傳文件                        │
│         ↓                                   │
│  Step 2: ✂️ 文件分割成小片段                │
│         ↓                                   │
│  Step 3: 🔢 將片段轉換為向量（Embedding）   │
│         ↓                                   │
│  Step 4: 💾 儲存到記憶體（In-Memory Store） │
│         ↓                                   │
│  Step 5: 💬 使用者提問                      │
│         ↓                                   │
│  Step 6: 🔍 語義搜尋相關片段                │
│         ↓                                   │
│  Step 7: 🤖 AI 根據片段生成答案             │
│                                             │
└─────────────────────────────────────────────┘
```

---

## 🏗️ 系統架構

### **節點說明**

```
┌──────────────────────────────────────────────────────────┐
│                    單一工作流程                           │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  [上傳檔案] (Form Trigger)                               │
│      ↓                                                   │
│  [Simple Vector Store] (Insert Mode) ←─ [Embeddings]    │
│      ↑                                                   │
│  [Default Data Loader]                                   │
│                                                          │
│  ─────────────────────────────────────────────────────   │
│                                                          │
│  [When chat message received] (Chat Trigger)             │
│      ↓                                                   │
│  [將中文轉換為英文] (Ollama)                              │
│      ↓                                                   │
│  [AI Agent] ←─ [Ollama Chat Model]                      │
│      ↓                                                   │
│  [Simple Vector Store1] (Retrieve) ←─ [Embeddings]      │
│                                                          │
└──────────────────────────────────────────────────────────┘
```

### **流程架構圖**

![流程架構圖](./images/RAG入門_記憶體儲存.png)

### **流程圖下載**

[RAG入門_記憶體儲存.json](./RAG入門_記憶體儲存.json)

### **節點詳細說明**

這個工作流程分為**兩個主要流程**：

#### **🔵 流程一：檔案上傳與向量化儲存**（左側）

---

##### **1️⃣ 上傳檔案（Form Trigger）**

- **節點類型**：`n8n-nodes-base.formTrigger` v2.5
- **主要功能**：
  - 產生一個網頁表單，讓使用者可以上傳檔案
  - 接受 `.txt`、`.pdf` 和 `.csv` 格式的檔案
  - 表單標題：「上傳資料至記憶體」
  - 表單描述：「將csv,txt,pdf檔案上傳至記憶體資料庫」
  - 這是整個流程的**起始點**

**💡 學習重點**：
- 這就像是一個「入口大門」，使用者在這裡上傳他們的資料
- n8n 會自動產生一個網址，可以分享給其他人使用
- 支援多檔案上傳，一次可以處理多個文件
- **注意**：此範例為「英轉英」範例，建議上傳英文檔案

---

##### **2️⃣ Default Data Loader**

- **節點類型**：`documentDefaultDataLoader` v1.1
- **資料類型**：Binary（二進位）
- **主要功能**：
  - 讀取二進位檔案（Binary Data）
  - 將 PDF 或 CSV 內容解析成文字
  - 準備好讓向量資料庫處理

**💡 學習重點**：
- 這是一個「翻譯員」，把檔案變成 AI 能理解的格式
- 自動處理不同格式的文件
- 將非結構化資料轉換為結構化文字

---

##### **3️⃣ Embeddings HuggingFace Inference**

- **節點類型**：`embeddingsHuggingFaceInference` v1
- **使用模型**：`sentence-transformers/all-MiniLM-L6-v2`
- **主要功能**：
  - 將文字轉換成向量（Embedding）
  - 連接到 HuggingFace API
  - 同時供應兩個節點使用（插入和查詢）

**💡 學習重點**：
- 這是整個系統的**核心技術**
- Embedding 就像是把文字轉換成「座標」，讓電腦能計算文字之間的相似度
- 同一個 Embedding 模型連接到兩個地方，確保「存入」和「查詢」使用相同的向量化方式
- `sentence-transformers/all-MiniLM-L6-v2` 是一個輕量級的英文嵌入模型，速度快且效果好
- **注意**：此模型主要針對英文優化，適合此「英轉英」範例

---

##### **4️⃣ Simple Vector Store（Insert 模式）**

- **節點類型**：`vectorStoreInMemory` v1.3
- **運作模式**：`insert`（插入模式）
- **Memory Key**：`vector_store_key`
- **Embedding Batch Size**：20
- **主要功能**：
  - 接收來自表單的檔案
  - 將檔案內容轉換成**向量**並儲存在記憶體中
  - 使用共享的記憶體金鑰，讓查詢節點可以存取

**💡 學習重點**：
- 這就像一個「智慧型資料庫」
- 它不是單純儲存文字，而是將內容轉換成數學向量
- 這樣 AI 才能「理解」文件的意義並進行語義搜尋
- **Memory Key** 是關鍵：讓兩個 Vector Store 節點共享同一個資料庫
- **Embedding Batch Size** 控制一次處理的文件片段數量，影響處理速度

---

#### **🟢 流程二：AI 聊天查詢**（右側）

---

##### **5️⃣ When chat message received（Chat Trigger）**

- **節點類型**：`chatTrigger` v1.4
- **主要功能**：
  - 提供一個聊天介面
  - 接收使用者的問題（可以是中文）
  - 啟動 AI 代理處理流程

**💡 學習重點**：
- 這是另一個「入口」，但這次是用來問問題的
- n8n 會產生一個聊天室網址，使用者可以在那裡和 AI 對話
- 與表單觸發器分開，形成兩個獨立的觸發點
- 使用者可以用中文提問，系統會自動轉換為英文進行檢索

---

##### **6️⃣ 將中文轉換為英文**

- **節點類型**：`ollama` v1
- **使用模型**：`gpt-oss:20b-cloud`
- **主要功能**：
  - 接收使用者的中文問題
  - 將中文問題轉換為英文
  - System Prompt：「你的工作是把這些輸入的文字,完整的轉換為英文,不要加入任何其它的文字」

**💡 學習重點**：
- 這是「英轉英」範例的關鍵節點
- 因為 Embedding 模型主要針對英文優化，所以需要先將中文問題轉換為英文
- 轉換後的英文問題會用於向量檢索
- 使用 Ollama 本地模型進行翻譯，無需額外 API 費用

---

##### **7️⃣ AI Agent**

- **節點類型**：`agent` v3.1
- **System Message**：繁體中文，定義為「信用卡權益說明文件的專業助理」
- **主要功能**：
  - 接收轉換後的英文問題
  - 決定要使用哪些工具來回答
  - 整合所有資訊後產生繁體中文回答

**💡 學習重點**：
- 這是整個 AI 系統的**「大腦」**
- 它會判斷：「我需要去資料庫找資料嗎？」「找到的資料要怎麼整合？」
- 它可以多次呼叫工具，直到找到最佳答案
- AI Agent 會自己判斷要不要使用工具，工具的描述很重要
- System Message 明確要求只能根據文件內容回答，使用繁體中文回應

---

##### **8️⃣ Ollama Chat Model**

- **節點類型**：`lmChatOllama` v1
- **使用模型**：`gpt-oss:20b-cloud`
- **主要功能**：
  - 提供語言理解和生成能力
  - 使用本地 Ollama 模型，無需 API 費用
  - 產生自然語言回答（繁體中文）

**💡 學習重點**：
- 這是 AI 的**「語言能力」**
- 就像給 AI 一個「會說話的嘴巴」
- 使用本地 Ollama 模型，完全免費且隱私性高
- 需要在本地安裝並啟動 Ollama 服務
- 模型會根據檢索到的英文資料生成繁體中文回答

---

##### **9️⃣ Simple Vector Store1（Retrieve 模式）**

- **節點類型**：`vectorStoreInMemory` v1.3
- **運作模式**：`retrieve-as-tool`（作為工具檢索）
- **Memory Key**：`vector_store_key`（與插入節點共享）
- **工具描述**：「請使用這裏的資料知識回答使用者」（繁體中文）
- **主要功能**：
  - 從向量資料庫中搜尋相關文件
  - 根據轉換後的英文問題找出最相關的內容
  - 將找到的英文資料提供給 AI Agent

**💡 學習重點**：
- 這是 AI 的**「參考資料工具」**
- AI Agent 可以主動決定要不要使用這個工具
- 它會找出和問題最相關的片段，而不是整份文件
- 使用相同的 Memory Key，存取之前儲存的向量資料
- 工具描述使用繁體中文，幫助 AI Agent 理解何時使用此工具

---

## 🔄 完整運作流程

理解了每個節點的功能後，讓我們看看整個系統是如何運作的：

### **🔵 階段一：建立知識庫**

```
使用者上傳檔案 (Form Trigger)
    ↓
Default Data Loader 解析檔案
    ↓ (提取文字內容)
Embeddings 將文字向量化
    ↓ (轉換為數字向量)
Simple Vector Store 儲存向量
    ✅ (知識庫建立完成)
```

**詳細步驟**：
1. 使用者在網頁表單上傳 PDF 或 CSV 檔案
2. Default Data Loader 讀取檔案並提取文字內容
3. Embeddings 節點將文字轉換為向量（例如：1536 維度的數字陣列）
4. Simple Vector Store 將向量儲存在記憶體中，使用 `vector_store_key` 標識
5. 系統回傳「上傳成功」訊息

---

### **🟢 階段二：AI 智能問答**

```
使用者提問（中文）(Chat Trigger)
    ↓
將中文轉換為英文 (Ollama)
    ↓ (翻譯問題)
AI Agent 接收英文問題並分析
    ↓ (決策：需要查資料嗎？)
AI Agent 呼叫 Simple Vector Store1
    ↓ (搜尋相關片段)
Simple Vector Store1 從 Vector Store 檢索資料
    ↓ (返回最相關的英文內容)
AI Agent 整合資料
    ↓ (組織答案)
Ollama Chat Model 生成繁體中文回答
    ↓
回答顯示在聊天介面
    ✅ (完成)
```

**詳細步驟**：
1. 使用者在聊天介面輸入中文問題
2. 「將中文轉換為英文」節點將問題翻譯為英文
3. AI Agent 接收英文問題並判斷：「這個問題需要查詢知識庫嗎？」
4. 如果需要，AI Agent 呼叫 Simple Vector Store1
5. Simple Vector Store1 將英文問題轉換為向量，並在 Vector Store 中搜尋最相似的文件片段
6. 找到的相關英文片段回傳給 AI Agent
7. AI Agent 將問題和找到的資料一起傳給 Ollama Chat Model
8. Chat Model 根據英文資料生成繁體中文回答
9. 回答顯示在聊天介面上

---

### **🔑 兩個流程的連接點：Memory Key**

```
┌─────────────────────────────────────┐
│    vector_store_key (共享)           │
├─────────────────────────────────────┤
│                                     │
│  流程一：寫入 (Insert)               │
│  Simple Vector Store → 儲存向量      │
│                                     │
│  流程二：讀取 (Retrieve)             │
│  Query Data Tool → 檢索向量          │
│                                     │
└─────────────────────────────────────┘
```

**重要概念**：
- 兩個流程使用**相同的 Memory Key**（`vector_store_key`）
- 這讓它們能夠共享同一個向量資料庫
- 流程一負責「寫入」，流程二負責「讀取」
- 它們是獨立的觸發器，可以分別執行

---

## 🚀 快速開始（5 分鐘）

### **前置需求**

- ✅ n8n 帳號（本地安裝或雲端版都可）
- ✅ HuggingFace API Key（[免費申請](https://huggingface.co/settings/tokens)）
- ✅ Ollama 已安裝並啟動（[安裝指南](../../Ollama安裝與設定.md)）
- ✅ 已下載 `gpt-oss:20b-cloud` 模型（執行 `ollama pull gpt-oss:20b-cloud`）

### **步驟 1：匯入工作流程**

1. 下載 `RAG入門_記憶體儲存.json`
2. 在 n8n 中點擊 **Import from File**
3. 選擇檔案並匯入

### **步驟 2：設定憑證**

#### **2.1 HuggingFace API**

1. 前往 [HuggingFace Tokens](https://huggingface.co/settings/tokens)
2. 建立新 Token（Read 權限即可）
3. 在 n8n 中新增 `HuggingFaceApi` 憑證
4. 貼上您的 API Token

#### **2.2 Ollama 設定**

1. 確認 Ollama 已安裝並正在運行（預設在 `http://localhost:11434`）
2. 下載所需模型：
   ```bash
   ollama pull gpt-oss:20b-cloud
   ```
3. 驗證模型已安裝：
   ```bash
   ollama list
   ```
4. 在 n8n 中新增 `Ollama API` 憑證
5. Base URL 設定為：`http://localhost:11434`（或您的 Ollama 服務地址）

### **步驟 3：取得上傳網址**

1. 開啟工作流程
2. 點擊 `上傳檔案` 節點
3. 複製 **Production URL**
4. 在瀏覽器中開啟該網址

### **步驟 4：上傳測試文件**

1. 準備一個英文的 TXT、PDF 或 CSV 檔案（建議小於 5MB）
   - 範例檔案：`信用卡權益說明_en.txt`（可在知識庫文件資料夾中找到）
2. 在表單中上傳檔案
3. 等待處理完成（約 10-30 秒）

**⚠️ 重要提醒**：
- 此範例為「英轉英」範例，請上傳**英文檔案**
- Embedding 模型 `sentence-transformers/all-MiniLM-L6-v2` 主要針對英文優化

### **步驟 5：開始問答**

1. 回到 n8n 工作流程
2. 點擊 `When chat message received` 節點
3. 複製 **Chat URL**
4. 在瀏覽器中開啟聊天介面
5. 開始提問！

---

## 💡 測試範例

### **測試 1：簡單事實查詢**

**上傳文件**：`信用卡權益說明_en.txt`（英文檔案）

### 測試題 1｜年費理解（基本準確度）

使用者 Prompt

```
Premium Cash Back Credit Card 的正卡與附卡年費是多少？什麼情況下第二年可以免年費？
```

**正確解答**
- 正卡年費：新臺幣 3,000 元
- 附卡年費：新臺幣 1,500 元
- 首年免年費
- 第二年若年度消費達新臺幣 120,000 元，可免年費

⸻

#### 測試題 2｜回饋比例（條件判斷）

使用者 Prompt

```
Premium Cash Back Credit Card 在國內與海外消費的現金回饋比例各是多少？
```

**正確解答**
- 國內消費現金回饋：1.2%
- 海外消費現金回饋：2.5%

⸻

#### 測試題 3｜點數計算（數學＋條件）

使用者 Prompt

```
使用 Bonus Points Card，在生日當月於指定超市消費新臺幣 1,000 元，可以獲得多少點數？
```

**正確解答**
- 指定商店點數累積：每新臺幣 10 元 = 1 點
- 1,000 ÷ 10 = 100 點
- 生日當月點數加倍
- 實得點數：200 點

⸻

#### 測試題 4｜現金回饋上限（陷阱題）

使用者 Prompt

```
Premium Cash Back Credit Card 的國內與海外現金回饋，每月與每年各有什麼上限？
```

**正確解答**
- 國內消費：
- 每月現金回饋上限為新臺幣 1,000 元
- 海外消費：
- 每月現金回饋上限為新臺幣 2,000 元
- 全年現金回饋上限：
- 新臺幣 30,000 元

⸻

#### 測試題 5｜海外實際回饋率（理解能力）

使用者 Prompt

```
若海外消費新臺幣 100,000 元，包含 1.5% 國外交易手續費，實際可得到多少現金回饋？實質回饋率是多少？
```

**正確解答**
- 原始回饋：
- 100,000 × 2.5% = 2,500 元
- 國外交易手續費：
- 100,000 × 1.5% = 1,500 元
- 實際淨回饋金額：
- 2,500 − 1,500 = 1,000 元
- 實質回饋率：
- 1.0%

⸻

#### 測試題 6｜分期費用計算（長答案）

使用者 Prompt

```
若以一般分期購買手機 30,000 元，選擇 12 期，總共需支付多少？每期多少？
```

**正確解答**
- 12 期分期手續費率：7.5%
- 手續費：
- 30,000 × 7.5% = 2,250 元
- 總支付金額：
- 30,000 + 2,250 = 32,250 元
- 每期金額：
- 32,250 ÷ 12 ≈ 2,687 元

⸻

#### 測試題 7｜保險啟用條件（條件型 RAG）

使用者 Prompt

```
旅遊不便險需要符合什麼刷卡條件才會生效？
```

**正確解答**
- 必須使用信用卡支付 80% 以上的機票或團費
- 符合後即可享有航班延誤、行李延誤、行李遺失及旅程取消等保障

⸻

#### 測試題 8｜機場接送權益（細節檢索）

使用者 Prompt

```
Premium Card 每年可享有幾次免費機場接送？需要提前多久預約？
```

**正確解答**
- 每年免費機場接送次數：4 次
- 必須於出發前 3 天 進行預約

⸻

#### 測試題 9｜爭議款項處理時效（流程理解）

使用者 Prompt

```
信用卡交易爭議向銀行提出後，調查時間大約多久？
```

**正確解答**
- 銀行調查期間約為 30 至 60 天
- 若涉及國際卡組織，最長可達 120 天

⸻

#### 測試題 10｜文件不存在測試（防幻覺）

使用者 Prompt

```
這張信用卡是否提供加密貨幣消費回饋？
```

**正確解答
- 文件中未提及此項權益
---

### **為什麼要將中文轉換為英文？**
此範例使用的 Embedding 模型主要針對英文優化。如果想直接使用中文，可更換為多語言模型（如 `BAAI/bge-m3`）並移除「將中文轉換為英文」節點。

---


**💡 下一步**：前往 [基礎版](../02_基礎版_簡單向量儲存/README.md) 學習資料持久化和多來源整合！
