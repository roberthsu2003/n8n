# 🎯 RAG 入門版 - 記憶體儲存

## 📖 什麼是這個範例？

這是 **最簡單的 RAG 實作**，讓您在 5 分鐘內體驗 RAG（檢索增強生成）技術的魅力！

整個系統只需要**一個工作流程**，就能實現：
- 📤 上傳文件（PDF,CSV,TXT）
- 🔍 自動建立向量索引
- 💬 智能問答對話（支援中文提問，英文檢索，中文回答）

### 🌍 範例特色：英轉英架構

此範例採用「**英轉英**」架構：
- 📄 **上傳英文檔案**：使用英文 Embedding 模型（`sentence-transformers/all-MiniLM-L6-v2`）獲得最佳檢索效果
- 💬 **中文提問**：使用者可以用繁體中文提問
- 🔄 **自動翻譯**：系統自動將中文問題轉換為英文進行向量檢索
- ✅ **中文回答**：AI 根據檢索到的英文資料生成繁體中文回答

**為什麼這樣設計？**
- 英文 Embedding 模型對英文文件的檢索效果最佳
- 使用者可以用熟悉的語言（中文）提問
- 系統自動處理語言轉換，無需手動翻譯

### 範例知識庫文件下載

[範例知識庫文件下載](../知識庫文件)

**建議使用**：`信用卡權益說明_en.txt`（英文檔案）

## ✨ 核心特色

### **為什麼從這裡開始？**

| 特點 | 說明 |
|------|------|
| 🚀 **超級簡單** | 只需一個工作流程，5分鐘快速體驗 |
| 💾 **記憶體儲存** | 使用 In-Memory Vector Store，無需外部資料庫 |
| 🆓 **零成本** | 使用 HuggingFace 免費嵌入模型 + Ollama 本地模型 |
| ⚡ **即時體驗** | 上傳檔案後立即可以開始問答 |
| 📚 **學習友善** | 專注於 RAG 核心概念，無額外複雜度 |
| 🌍 **多語言支援** | 支援中文提問，英文檢索，中文回答 |

### **適用場景**

✅ RAG 技術學習和概念驗證  
✅ 快速測試和演示  
✅ 個人小規模使用（少量文件）  
✅ 教學和實驗

### **限制與注意事項**

⚠️ **資料不持久**：工作流程重啟或執行結束後，向量資料會消失  
⚠️ **不適合大量文件**：記憶體有限，建議小於 50 份文件  
⚠️ **無法跨流程共用**：每次執行都是獨立的索引  
⚠️ **適合測試**：生產環境建議使用基礎版或進階版  
⚠️ **英轉英範例**：此範例針對英文檔案優化，請上傳英文檔案以獲得最佳效果  
⚠️ **需要 Ollama**：需要本地安裝並運行 Ollama 服務

---

## 🎓 什麼是 RAG？

**RAG (Retrieval-Augmented Generation)** = 檢索增強生成

簡單來說，RAG 讓 AI 能夠：
1. 📖 **讀取**您的文件
2. 🔍 **檢索**相關資訊
3. 💬 **回答**基於文件內容的問題

### **RAG 的工作流程**

```
┌─────────────────────────────────────────────┐
│          RAG 工作流程（入門版）              │
├─────────────────────────────────────────────┤
│                                             │
│  Step 1: 📤 上傳文件                        │
│         ↓                                   │
│  Step 2: ✂️ 文件分割成小片段                │
│         ↓                                   │
│  Step 3: 🔢 將片段轉換為向量（Embedding）   │
│         ↓                                   │
│  Step 4: 💾 儲存到記憶體（In-Memory Store） │
│         ↓                                   │
│  Step 5: 💬 使用者提問                      │
│         ↓                                   │
│  Step 6: 🔍 語義搜尋相關片段                │
│         ↓                                   │
│  Step 7: 🤖 AI 根據片段生成答案             │
│                                             │
└─────────────────────────────────────────────┘
```

---

## 🏗️ 系統架構

### **節點說明**

```
┌──────────────────────────────────────────────────────────┐
│                    單一工作流程                           │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  [上傳檔案] (Form Trigger)                               │
│      ↓                                                   │
│  [Simple Vector Store] (Insert Mode) ←─ [Embeddings]    │
│      ↑                                                   │
│  [Default Data Loader]                                   │
│                                                          │
│  ─────────────────────────────────────────────────────   │
│                                                          │
│  [When chat message received] (Chat Trigger)             │
│      ↓                                                   │
│  [將中文轉換為英文] (Ollama)                              │
│      ↓                                                   │
│  [AI Agent] ←─ [Ollama Chat Model]                      │
│      ↓                                                   │
│  [Simple Vector Store1] (Retrieve) ←─ [Embeddings]      │
│                                                          │
└──────────────────────────────────────────────────────────┘
```

### **流程架構圖**

![流程架構圖](./images/RAG入門_記憶體儲存.png)

### **流程圖下載**

[RAG入門_記憶體儲存.json](./RAG入門_記憶體儲存.json)

### **節點詳細說明**

這個工作流程分為**兩個主要流程**：

#### **🔵 流程一：檔案上傳與向量化儲存**（左側）

---

##### **1️⃣ 上傳檔案（Form Trigger）**

- **節點類型**：`n8n-nodes-base.formTrigger` v2.5
- **主要功能**：
  - 產生一個網頁表單，讓使用者可以上傳檔案
  - 接受 `.txt`、`.pdf` 和 `.csv` 格式的檔案
  - 表單標題：「上傳資料至記憶體」
  - 表單描述：「將csv,txt,pdf檔案上傳至記憶體資料庫」
  - 這是整個流程的**起始點**

**💡 學習重點**：
- 這就像是一個「入口大門」，使用者在這裡上傳他們的資料
- n8n 會自動產生一個網址，可以分享給其他人使用
- 支援多檔案上傳，一次可以處理多個文件
- **注意**：此範例為「英轉英」範例，建議上傳英文檔案

---

##### **2️⃣ Default Data Loader**

- **節點類型**：`documentDefaultDataLoader` v1.1
- **資料類型**：Binary（二進位）
- **主要功能**：
  - 讀取二進位檔案（Binary Data）
  - 將 PDF 或 CSV 內容解析成文字
  - 準備好讓向量資料庫處理

**💡 學習重點**：
- 這是一個「翻譯員」，把檔案變成 AI 能理解的格式
- 自動處理不同格式的文件
- 將非結構化資料轉換為結構化文字

---

##### **3️⃣ Embeddings HuggingFace Inference**

- **節點類型**：`embeddingsHuggingFaceInference` v1
- **使用模型**：`sentence-transformers/all-MiniLM-L6-v2`
- **主要功能**：
  - 將文字轉換成向量（Embedding）
  - 連接到 HuggingFace API
  - 同時供應兩個節點使用（插入和查詢）

**💡 學習重點**：
- 這是整個系統的**核心技術**
- Embedding 就像是把文字轉換成「座標」，讓電腦能計算文字之間的相似度
- 同一個 Embedding 模型連接到兩個地方，確保「存入」和「查詢」使用相同的向量化方式
- `sentence-transformers/all-MiniLM-L6-v2` 是一個輕量級的英文嵌入模型，速度快且效果好
- **注意**：此模型主要針對英文優化，適合此「英轉英」範例

---

##### **4️⃣ Simple Vector Store（Insert 模式）**

- **節點類型**：`vectorStoreInMemory` v1.3
- **運作模式**：`insert`（插入模式）
- **Memory Key**：`vector_store_key`
- **Embedding Batch Size**：20
- **主要功能**：
  - 接收來自表單的檔案
  - 將檔案內容轉換成**向量**並儲存在記憶體中
  - 使用共享的記憶體金鑰，讓查詢節點可以存取

**💡 學習重點**：
- 這就像一個「智慧型資料庫」
- 它不是單純儲存文字，而是將內容轉換成數學向量
- 這樣 AI 才能「理解」文件的意義並進行語義搜尋
- **Memory Key** 是關鍵：讓兩個 Vector Store 節點共享同一個資料庫
- **Embedding Batch Size** 控制一次處理的文件片段數量，影響處理速度

---

#### **🟢 流程二：AI 聊天查詢**（右側）

---

##### **5️⃣ When chat message received（Chat Trigger）**

- **節點類型**：`chatTrigger` v1.4
- **主要功能**：
  - 提供一個聊天介面
  - 接收使用者的問題（可以是中文）
  - 啟動 AI 代理處理流程

**💡 學習重點**：
- 這是另一個「入口」，但這次是用來問問題的
- n8n 會產生一個聊天室網址，使用者可以在那裡和 AI 對話
- 與表單觸發器分開，形成兩個獨立的觸發點
- 使用者可以用中文提問，系統會自動轉換為英文進行檢索

---

##### **6️⃣ 將中文轉換為英文**

- **節點類型**：`ollama` v1
- **使用模型**：`gpt-oss:20b-cloud`
- **主要功能**：
  - 接收使用者的中文問題
  - 將中文問題轉換為英文
  - System Prompt：「你的工作是把這些輸入的文字,完整的轉換為英文,不要加入任何其它的文字」

**💡 學習重點**：
- 這是「英轉英」範例的關鍵節點
- 因為 Embedding 模型主要針對英文優化，所以需要先將中文問題轉換為英文
- 轉換後的英文問題會用於向量檢索
- 使用 Ollama 本地模型進行翻譯，無需額外 API 費用

---

##### **7️⃣ AI Agent**

- **節點類型**：`agent` v3.1
- **System Message**：繁體中文，定義為「信用卡權益說明文件的專業助理」
- **主要功能**：
  - 接收轉換後的英文問題
  - 決定要使用哪些工具來回答
  - 整合所有資訊後產生繁體中文回答

**💡 學習重點**：
- 這是整個 AI 系統的**「大腦」**
- 它會判斷：「我需要去資料庫找資料嗎？」「找到的資料要怎麼整合？」
- 它可以多次呼叫工具，直到找到最佳答案
- AI Agent 會自己判斷要不要使用工具，工具的描述很重要
- System Message 明確要求只能根據文件內容回答，使用繁體中文回應

---

##### **8️⃣ Ollama Chat Model**

- **節點類型**：`lmChatOllama` v1
- **使用模型**：`gpt-oss:20b-cloud`
- **主要功能**：
  - 提供語言理解和生成能力
  - 使用本地 Ollama 模型，無需 API 費用
  - 產生自然語言回答（繁體中文）

**💡 學習重點**：
- 這是 AI 的**「語言能力」**
- 就像給 AI 一個「會說話的嘴巴」
- 使用本地 Ollama 模型，完全免費且隱私性高
- 需要在本地安裝並啟動 Ollama 服務
- 模型會根據檢索到的英文資料生成繁體中文回答

---

##### **9️⃣ Simple Vector Store1（Retrieve 模式）**

- **節點類型**：`vectorStoreInMemory` v1.3
- **運作模式**：`retrieve-as-tool`（作為工具檢索）
- **Memory Key**：`vector_store_key`（與插入節點共享）
- **工具描述**：「請使用這裏的資料知識回答使用者」（繁體中文）
- **主要功能**：
  - 從向量資料庫中搜尋相關文件
  - 根據轉換後的英文問題找出最相關的內容
  - 將找到的英文資料提供給 AI Agent

**💡 學習重點**：
- 這是 AI 的**「參考資料工具」**
- AI Agent 可以主動決定要不要使用這個工具
- 它會找出和問題最相關的片段，而不是整份文件
- 使用相同的 Memory Key，存取之前儲存的向量資料
- 工具描述使用繁體中文，幫助 AI Agent 理解何時使用此工具

---

## 🔄 完整運作流程

理解了每個節點的功能後，讓我們看看整個系統是如何運作的：

### **🔵 階段一：建立知識庫**

```
使用者上傳檔案 (Form Trigger)
    ↓
Default Data Loader 解析檔案
    ↓ (提取文字內容)
Embeddings 將文字向量化
    ↓ (轉換為數字向量)
Simple Vector Store 儲存向量
    ✅ (知識庫建立完成)
```

**詳細步驟**：
1. 使用者在網頁表單上傳 PDF 或 CSV 檔案
2. Default Data Loader 讀取檔案並提取文字內容
3. Embeddings 節點將文字轉換為向量（例如：1536 維度的數字陣列）
4. Simple Vector Store 將向量儲存在記憶體中，使用 `vector_store_key` 標識
5. 系統回傳「上傳成功」訊息

---

### **🟢 階段二：AI 智能問答**

```
使用者提問（中文）(Chat Trigger)
    ↓
將中文轉換為英文 (Ollama)
    ↓ (翻譯問題)
AI Agent 接收英文問題並分析
    ↓ (決策：需要查資料嗎？)
AI Agent 呼叫 Simple Vector Store1
    ↓ (搜尋相關片段)
Simple Vector Store1 從 Vector Store 檢索資料
    ↓ (返回最相關的英文內容)
AI Agent 整合資料
    ↓ (組織答案)
Ollama Chat Model 生成繁體中文回答
    ↓
回答顯示在聊天介面
    ✅ (完成)
```

**詳細步驟**：
1. 使用者在聊天介面輸入中文問題
2. 「將中文轉換為英文」節點將問題翻譯為英文
3. AI Agent 接收英文問題並判斷：「這個問題需要查詢知識庫嗎？」
4. 如果需要，AI Agent 呼叫 Simple Vector Store1
5. Simple Vector Store1 將英文問題轉換為向量，並在 Vector Store 中搜尋最相似的文件片段
6. 找到的相關英文片段回傳給 AI Agent
7. AI Agent 將問題和找到的資料一起傳給 Ollama Chat Model
8. Chat Model 根據英文資料生成繁體中文回答
9. 回答顯示在聊天介面上

---

### **🔑 兩個流程的連接點：Memory Key**

```
┌─────────────────────────────────────┐
│    vector_store_key (共享)           │
├─────────────────────────────────────┤
│                                     │
│  流程一：寫入 (Insert)               │
│  Simple Vector Store → 儲存向量      │
│                                     │
│  流程二：讀取 (Retrieve)             │
│  Query Data Tool → 檢索向量          │
│                                     │
└─────────────────────────────────────┘
```

**重要概念**：
- 兩個流程使用**相同的 Memory Key**（`vector_store_key`）
- 這讓它們能夠共享同一個向量資料庫
- 流程一負責「寫入」，流程二負責「讀取」
- 它們是獨立的觸發器，可以分別執行

---

## 🚀 快速開始（5 分鐘）

### **前置需求**

- ✅ n8n 帳號（本地安裝或雲端版都可）
- ✅ HuggingFace API Key（[免費申請](https://huggingface.co/settings/tokens)）
- ✅ Ollama 已安裝並啟動（[安裝指南](../../Ollama安裝與設定.md)）
- ✅ 已下載 `gpt-oss:20b-cloud` 模型（執行 `ollama pull gpt-oss:20b-cloud`）

### **步驟 1：匯入工作流程**

1. 下載 `RAG入門_記憶體儲存.json`
2. 在 n8n 中點擊 **Import from File**
3. 選擇檔案並匯入

### **步驟 2：設定憑證**

#### **2.1 HuggingFace API**

1. 前往 [HuggingFace Tokens](https://huggingface.co/settings/tokens)
2. 建立新 Token（Read 權限即可）
3. 在 n8n 中新增 `HuggingFaceApi` 憑證
4. 貼上您的 API Token

#### **2.2 Ollama 設定**

1. 確認 Ollama 已安裝並正在運行（預設在 `http://localhost:11434`）
2. 下載所需模型：
   ```bash
   ollama pull gpt-oss:20b-cloud
   ```
3. 驗證模型已安裝：
   ```bash
   ollama list
   ```
4. 在 n8n 中新增 `Ollama API` 憑證
5. Base URL 設定為：`http://localhost:11434`（或您的 Ollama 服務地址）

### **步驟 3：取得上傳網址**

1. 開啟工作流程
2. 點擊 `上傳檔案` 節點
3. 複製 **Production URL**
4. 在瀏覽器中開啟該網址

### **步驟 4：上傳測試文件**

1. 準備一個英文的 TXT、PDF 或 CSV 檔案（建議小於 5MB）
   - 範例檔案：`信用卡權益說明_en.txt`（可在知識庫文件資料夾中找到）
2. 在表單中上傳檔案
3. 等待處理完成（約 10-30 秒）

**⚠️ 重要提醒**：
- 此範例為「英轉英」範例，請上傳**英文檔案**
- Embedding 模型 `sentence-transformers/all-MiniLM-L6-v2` 主要針對英文優化

### **步驟 5：開始問答**

1. 回到 n8n 工作流程
2. 點擊 `When chat message received` 節點
3. 複製 **Chat URL**
4. 在瀏覽器中開啟聊天介面
5. 開始提問！

---

## 💡 測試範例

### **測試 1：簡單事實查詢**

**上傳文件**：`信用卡權益說明_en.txt`（英文檔案）

**提問**（可用中文）：
```
這個信用卡的主要權益是什麼？
```

**預期結果**：AI 會將問題轉換為英文，從文件中找到相關內容，並以繁體中文回答

---

### **測試 2：步驟性問題**

**上傳文件**：使用手冊 PDF

**提問**：
```
如何設定初始密碼？
```

**預期結果**：AI 會提供清楚的步驟說明

---

### **測試 3：找不到答案**

**提問**：
```
明天天氣如何？
```

**預期結果**：AI 應該回答「文件中沒有相關資訊」

---

## 🎯 核心概念理解

### **1. Embeddings（嵌入）是什麼？**

**簡單比喻**：將文字轉換為數字向量，讓電腦能理解「意義」

```
文字：「貓是一種可愛的動物」
     ↓ (Embedding)
向量：[0.23, -0.45, 0.89, ..., 0.12]
```

**為什麼重要？**
- 電腦無法直接理解文字
- 向量可以計算「相似度」
- 語義相近的文字會有相似的向量

### **2. Vector Store（向量資料庫）**

**作用**：儲存文件的向量表示，並支援快速搜尋

**記憶體儲存 vs 持久化儲存**

| 特性 | In-Memory（本範例） | Simple Vector Store | 雲端資料庫（Pinecone） |
|------|---------------------|---------------------|----------------------|
| **資料持久性** | ❌ 執行結束即消失 | ✅ 儲存在本地檔案 | ✅ 儲存在雲端 |
| **適用規模** | 小（<50 文件） | 中（<1000 文件） | 大（無限制） |
| **設定複雜度** | 🟢 超簡單 | 🟡 簡單 | 🔴 需要註冊服務 |
| **成本** | 🆓 免費 | 🆓 免費 | 💳 付費（有免費額度） |

### **3. 語義搜尋 vs 關鍵字搜尋**

**關鍵字搜尋**（傳統方式）
```
問題：「如何重置密碼？」
搜尋：找包含「重置」和「密碼」的文字
問題：如果文件中寫的是「忘記密碼的解決方法」就找不到了
```

**語義搜尋**（RAG 使用）
```
問題：「如何重置密碼？」
轉換為向量後，能找到意義相近的內容：
  ✅ "忘記密碼的解決方法"
  ✅ "密碼變更步驟"
  ✅ "重新設定登入資訊"
```

---

## 🎓 重點整理

### **核心概念**

1. **兩個獨立觸發器**：表單觸發（上傳）和聊天觸發（問答）共享同一個 `vector_store_key`
2. **Embedding 一致性**：插入和檢索必須使用相同的 Embedding 模型，才能正確計算相似度
3. **Memory Key 共享**：兩個 Vector Store 節點使用相同的 Memory Key 才能共享資料
4. **RAG 三要素**：R（檢索）+ A（增強）+ G（生成）= 完整的 RAG 系統
5. **英轉英架構**：中文提問 → 轉英文 → 英文檢索 → 中文回答

---

## 💪 動手練習

### **練習 1：測試不同問題類型**
上傳文件後測試：簡單事實、需要理解、需要推理、超出範圍的問題，觀察 AI 如何回答。

### **練習 2：理解 Memory Key**
修改檢索節點的 Memory Key 為 `different_key`，觀察會發生什麼（應該會失敗），然後改回 `vector_store_key`。

### **練習 3：測試「英轉英」流程**
上傳英文檔案，用中文提問，觀察執行日誌中「將中文轉換為英文」節點的翻譯結果。

---

## 🔧 進階調整

### **更換模型**
- **Embedding**：可更換為 `BAAI/bge-m3`（多語言，支援中文），若更換可考慮移除「將中文轉換為英文」節點
- **Chat Model**：可更換為其他 Ollama 模型（如 `llama3.2:3b`、`qwen2.5:7b`）

### **調整參數**
- **Top K**：預設 4，可調整為 6-8 提高準確度（但會增加處理時間）

### **移除中文轉英文（進階）**
更換為多語言 Embedding 模型後，可移除「將中文轉換為英文」節點，直接使用中文檢索。

---

## ❓ 常見問題

### **Q1: 文件上傳後無法問答？**
- 檢查兩個 Vector Store 節點的 `Memory Key` 都設為 `vector_store_key`
- 確認 Ollama 服務正在運行：`curl http://localhost:11434/api/tags`
- **確認上傳的是英文檔案**（此範例為「英轉英」）

### **Q2: 重新執行後文件不見了？**
這是正常的！In-Memory Vector Store 的資料儲存在記憶體中，每次執行都是全新的索引。如需持久化，請升級到基礎版或進階版。

### **Q3: Ollama 連接失敗？**
- 確認 Ollama 正在運行：`curl http://localhost:11434/api/tags`
- 檢查 n8n 中的 Ollama API 憑證設定，Base URL 應為 `http://localhost:11434`

### **Q4: 為什麼要將中文轉換為英文？**
此範例使用的 Embedding 模型主要針對英文優化。如果想直接使用中文，可更換為多語言模型（如 `BAAI/bge-m3`）並移除「將中文轉換為英文」節點。

---

## 📚 學習路徑

### **完成這個範例後，您已經學會：**

✅ RAG 的基本概念和工作流程  
✅ Embeddings（嵌入）的作用  
✅ Vector Store（向量資料庫）的運作原理  
✅ 語義搜尋 vs 關鍵字搜尋的差異  
✅ AI Agent 如何使用工具檢索資訊  
✅ 多語言 RAG 系統的設計（中文提問、英文檢索、中文回答）  
✅ Ollama 本地模型的整合與使用

### **下一步學習建議：**

1. **📁 基礎版 - 簡單向量儲存**
   - 學習資料持久化
   - 分離索引和問答流程
   - 多來源整合（本機 + Google Drive）

2. **☁️ 進階版 - 雲端向量資料庫**
   - 使用 Pinecone、Qdrant 等專業資料庫
   - 學習大規模文件管理
   - 企業級應用設計

---

## 🎓 教學建議（45 分鐘）

1. **概念講解（15 分鐘）**：RAG 基本概念、Embeddings、Vector Store、語義搜尋
2. **實作演示（20 分鐘）**：匯入工作流程、設定憑證、上傳測試文件、執行問答測試
3. **互動實驗（10 分鐘）**：學生上傳文件、測試不同問題、觀察執行日誌、討論結果

---

## 📖 參考資源

- [n8n RAG 完整指南](https://docs.n8n.io/advanced-ai/rag-in-n8n/)
- [n8n AI Agent 文件](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/)
- [Vector Store 說明](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.vectorstoreinmemory/)

---

## 🎉 完成檢查清單

- [ ] 成功匯入工作流程並設定憑證（HuggingFace + Ollama）
- [ ] 確認 Ollama 服務運行並下載 `gpt-oss:20b-cloud` 模型
- [ ] 上傳英文測試文件並成功進行問答對話
- [ ] 理解 RAG 基本工作流程和「英轉英」架構
- [ ] 準備好學習基礎版或進階版

---

**🎓 恭喜完成 RAG 入門！您已經掌握了 RAG 的核心概念。**

**💡 下一步**：前往 [基礎版](../02_基礎版_簡單向量儲存/README.md) 學習資料持久化和多來源整合！
